<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>最大熵模型 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Logistic RegressionLogistic Distribution设$X$是连续随机变量，$X$服从 logistic distribution 是指$X$具有下列分布函数和密度函数： $$\begin{align}F(x) &amp;&#x3D; P(X \leq x) &#x3D; \frac{1}{1 + e^{-(x-\mu)&#x2F;\gamma}} \tag{1}\f(">
<meta property="og:type" content="article">
<meta property="og:title" content="最大熵模型">
<meta property="og:url" content="https://ddccffq.github.io/2025/06/02/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Logistic RegressionLogistic Distribution设$X$是连续随机变量，$X$服从 logistic distribution 是指$X$具有下列分布函数和密度函数： $$\begin{align}F(x) &amp;&#x3D; P(X \leq x) &#x3D; \frac{1}{1 + e^{-(x-\mu)&#x2F;\gamma}} \tag{1}\f(">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-06-02T02:02:23.000Z">
<meta property="article:modified_time" content="2025-06-06T03:38:47.000Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="算法">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://ddccffq.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-最大熵模型" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/06/02/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time class="dt-published" datetime="2025-06-02T02:02:23.000Z" itemprop="datePublished">2025-06-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>►<a class="article-category-link" href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      最大熵模型
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><h3 id="Logistic-Distribution"><a href="#Logistic-Distribution" class="headerlink" title="Logistic Distribution"></a>Logistic Distribution</h3><p>设$X$是连续随机变量，$X$服从 <strong>logistic distribution</strong> 是指$X$具有下列分布函数和密度函数：</p>
<p>$$<br>\begin{align}<br>F(x) &amp;&#x3D; P(X \leq x) &#x3D; \frac{1}{1 + e^{-(x-\mu)&#x2F;\gamma}} \tag{1}<br>\<br>f(x) &amp;&#x3D; F’(x) &#x3D; \frac{e^{-(x-\mu)&#x2F;\gamma}}{\gamma\left(1 + e^{-(x-\mu)&#x2F;\gamma}\right)^2} \tag{2}<br>\end{align}<br>$$</p>
<h3 id="Binomial-Logistic-Regression-Model"><a href="#Binomial-Logistic-Regression-Model" class="headerlink" title="Binomial Logistic Regression Model"></a>Binomial Logistic Regression Model</h3><p>这是一种二分类模型，这里规定模型输出 $Y \in {0, 1}$， 也就是 $y_i \in {0, 1}$</p>
<p>$$<br>\begin{align}<br>P(Y &#x3D; 0 | \mathbf{x}) &amp;&#x3D; \frac{1}{1 + \exp (\mathbf{w} \cdot \mathbf{x} + b)} \tag{3}<br>\<br>P(Y &#x3D; 1 | \mathbf{x}) &amp;&#x3D; \frac{\exp (\mathbf{w} \cdot \mathbf{x} + b)}{1 + \exp (\mathbf{w} \cdot \mathbf{x} + b)} \tag{4}<br>\end{align}<br>$$</p>
<p>其中，$\mathbf{x} \in \mathbb{R}^n$ 是输入，$\mathbf{w} \in \mathbb{R}^n$ 和 $ b \in \mathbb{R}$ 分别是权值向量和偏置，$\mathbf{w} \cdot \mathbf{x}$ 是向量内积运算。</p>
<h3 id="Evaluation-of-Model-Parameters"><a href="#Evaluation-of-Model-Parameters" class="headerlink" title="Evaluation of Model Parameters"></a>Evaluation of Model Parameters</h3><p>采用极大似然估计法估计模型参数，从而得到 <em><strong>logistics regression model</strong></em>。</p>
<p>我们设</p>
<p>$$<br>P(Y &#x3D; 1 | x) &#x3D; \pi(x) \tag{5}<br>$$</p>
<p>则得到似然函数为</p>
<p>$$<br>\prod_{i&#x3D;1}^{N}[\pi(x_i)]^{y_i}[1 - \pi(x_i)]^{1 - y_i} \tag{6}<br>$$</p>
<p>经过计算，对数似然函数为</p>
<p>$$<br>L(w) &#x3D; \sum_{i&#x3D;1}^{N} [y_i(\vec{w} \cdot \vec{x_i}) - \ln (1 + \exp (\vec{w} \cdot \vec{x_i}))] \tag{7}<br>$$</p>
<p>对 $L(w)$ 求极大值，得到 $w$ 的估计值 $\hat{w}$</p>
<hr>
<h2 id="Maximum-Entropy-Model"><a href="#Maximum-Entropy-Model" class="headerlink" title="Maximum Entropy Model"></a>Maximum Entropy Model</h2><h3 id="The-Principle-of-Maximum-Entropy"><a href="#The-Principle-of-Maximum-Entropy" class="headerlink" title="The Principle of Maximum Entropy"></a>The Principle of Maximum Entropy</h3><p>最大熵原理的核心在于，使得整个概率模型的熵最大。</p>
<h3 id="MaxEntropy-Model"><a href="#MaxEntropy-Model" class="headerlink" title="MaxEntropy Model"></a>MaxEntropy Model</h3><p>模型输入 $X \in \mathcal{X} \subseteq \mathbb{R}^n$，输出 $Y \in \mathcal{Y}$，条件概率分布 $P(Y | X)$ 表示对于给定输入 $X$ 以该条件概率输出 $Y$。</p>
<p>给定训练数据集，可以确定联合分布 $P(X, Y)$ 的经验分布和边缘分布。</p>
<p>$$<br>\begin{align}<br>\tilde{P}(X &#x3D; x, Y &#x3D; y) &amp;&#x3D; \frac{\nu(X &#x3D; x, Y &#x3D; y)}{N} \tag{8}<br>\<br>\tilde{P}(X &#x3D; x) &amp;&#x3D; \frac{\nu(X &#x3D; x)}{N} \tag{9}<br>\end{align}<br>$$</p>
<p>其中 $\nu(X &#x3D; x, Y &#x3D; y)$ 是样本 $(x, y)$ 出现的频数。</p>
<p>接下来介绍特征函数 <em><strong>feature function</strong></em> $f(x,y)$，$f()$ 描述输入 $x$ 与输出 $y$ 之间的某一个事实。</p>
<p>$$<br>f(x, y) &#x3D;<br>\begin{cases}<br>1, &amp;\text{satisfying}<br>\<br>0, &amp;\text{otherwise} \tag{10}<br>\end{cases}<br>$$</p>
<p>特征函数关于经验分布的期望值</p>
<p>$$<br>E_{\tilde{P}}(f) &#x3D; \sum_{x,y} \tilde{P}(x,y) f(x,y) \tag{11}<br>$$</p>
<p>特征函数关于模型与经验分布的期望值</p>
<p>$$<br>E_P(f) &#x3D; \sum_{x,y} \tilde{P}(x) P(y|x) f(x,y) \tag{12}<br>$$</p>
<p>如果模型能够获得训练数据中的信息，则可以认为上述两个期望值相等，即</p>
<p>$$<br>E_{\tilde{P}}(f) &#x3D; E_P(f) \tag{13}<br>$$</p>
<p>综上，我们引出最大熵模型。</p>
<p>假设满足所有约束条件的模型集合为</p>
<p>$$<br>\mathcal{C} \equiv {P \in \mathcal{P} \mid E_{\tilde{P}}(f_i) &#x3D; E_P(f_i), \quad i&#x3D;1,2,\dots,n} \tag{14}<br>$$</p>
<p>定义在条件概率分布 $P(Y|X)$ 上的条件熵为</p>
<p>$$<br>H(P) &#x3D; -\sum_{x,y} \tilde{P}(x) P(y|x) \ln P(y|x) \tag{15}<br>$$</p>
<p>则模型集合 $\mathcal{C}$ 中条件熵 $H(P)$ 最大的模型称为最大熵模型。</p>
<h3 id="Training-a-Maximum-Entropy-Model"><a href="#Training-a-Maximum-Entropy-Model" class="headerlink" title="Training a Maximum Entropy Model"></a>Training a Maximum Entropy Model</h3><p>类似 <strong>SVM</strong> 的学习过程。给定训练数据集 $T &#x3D; {(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)}$ 以及特征函数 $f_i(x,y), \quad i &#x3D; 1, 2, \dots, n$，最大熵模型的学习等价于约束最优化问题：</p>
<p>$$<br>\begin{align*}<br>\max_{P \in \mathcal{C}} \quad &amp; H(P) &#x3D; -\sum_{x, y} \tilde{P}(x) P(y \mid x) \ln P(y \mid x)<br>\<br>\text{subject to} \quad &amp; E_{\tilde{P}}[f_i] &#x3D; E_P[f_i], \quad i &#x3D; 1, 2, \dots, n<br>\<br>&amp; \sum_{y} P(y \mid x) &#x3D; 1<br>\end{align*}<br>$$</p>
<p>将其换为等价的最小化问题</p>
<p>$$<br>\begin{align*}<br>\min_{P \in \mathcal{C}} \quad -&amp;H(P) &#x3D; \sum_{x, y} \tilde{P}(x) P(y \mid x) \ln P(y \mid x) \tag{16}<br>\<br>\text{subject to} \quad &amp; E_{\tilde{P}}[f_i] - E_P[f_i]&#x3D; 0, \quad i &#x3D; 1, 2, \dots, n \tag{17}<br>\<br>&amp; \sum_{y} P(y \mid x) &#x3D; 1 \tag{18}<br>\end{align*}<br>$$</p>
<p>将约束最优化问题转换为无约束最优化的对偶问题。引入拉格朗日乘子 $w_0, w_1, \dots, w_n$，定义拉格朗日函数 $L(P, w)$：</p>
<p>$$<br>\begin{align*}<br>L(P, w) &amp;\equiv -H(P) + w_0 \left(1 - \sum_{y} P(y | x)\right) + \sum_{i &#x3D; 1}^{n} w_i (E_{\tilde{P}}(f_i) - E_{P}(f_i)) \tag{19}<br>\<br>&amp;&#x3D; \sum_{x,y} \tilde{P}(x) P(y | x) \ln P(y | x) + w_0\left(1 - \sum_{y} P(y | x)\right) +<br>\<br>&amp;\sum_{i &#x3D; 1}^{n} w_i\left(\sum_{x, y} \tilde{P}(x, y) f_i(x, y) - \sum_{x, y} \tilde{P}(x) P(y | x) f_i(x, y) \right)<br>\end{align*}<br>$$</p>
<p>最优化的原始问题是</p>
<p>$$<br>\min_{P \in \mathcal{C}} \max_{w} L(P, w) \tag{20}<br>$$</p>
<p>对偶问题是</p>
<p>$$<br>\max_{w} \min_{P \in \mathcal{C}} L(P, w) \tag{21}<br>$$</p>
<p>先解决极小化问题， 记</p>
<p>$$<br>\Psi(w) &#x3D; \min_{P \in \mathcal{C}} L(P, w) &#x3D; L(P_w, w) \tag{22}<br>$$</p>
<p>求 $L(P, w)$ 对 $P(y | x)$ 的偏导数</p>
<p>$$<br>\begin{align*}<br>\frac{\partial L(P, w)}{\partial P(y | x)} &amp;&#x3D; \sum_{x, y} \tilde{P}(x)(\ln P(y | x) + 1) - \sum_{y}w_0 - \sum_{x, y} \left(\tilde{P}(x) \sum_{i &#x3D; 1}^{n} w_i f_i(x, y) \right)<br>\<br>&amp;&#x3D; \sum_{x, y} \tilde{P}(x) \left(\ln P(y | x) + 1 - w_0 - \sum_{i &#x3D; 1}^{n} w_i f_i(x, y) \right)<br>\end{align*}<br>$$</p>
<p>令偏导数等于 $0$， 在 $\tilde{P} &gt; 0$ 的情况下，解得</p>
<p>$$<br>P_w(y | x) &#x3D; \frac{1}{Z_w(x)} \exp \left(\sum_{i &#x3D; 1}^{n} w_i f_i(x, y) \right) \tag{23}<br>$$</p>
<p>其中</p>
<p>$$<br>Z_w(x) &#x3D; \sum_{y} \exp \left(\sum_{i &#x3D; 1}^{n} w_i f_i(x, y) \right) \tag{24}<br>$$</p>
<p>称 $Z_w(x)$ 为归一化因子。</p>
<p>最后求解对偶问题外部的极大化问题</p>
<p>$$<br>\max_{w} \Psi(w) \tag{25}<br>$$</p>
<h3 id="Improved-Iterative-Scaling"><a href="#Improved-Iterative-Scaling" class="headerlink" title="Improved Iterative Scaling"></a>Improved Iterative Scaling</h3><p>已知最大熵模型</p>
<p>$$<br>P_w(y | x) &#x3D; \frac{1}{Z_w(x)} \exp \left(\sum_{i &#x3D; 1}^{n} w_i f_i(x, y) \right)<br>$$</p>
<p>其中</p>
<p>$$<br>Z_w(x) &#x3D; \sum_{y} \exp \left(\sum_{i &#x3D; 1}^{n} w_i f_i(x, y) \right)<br>$$</p>
<p>对数似然函数为</p>
<p>$$<br>L(w) &#x3D; \sum_{x, y} \tilde{P}(x, y) \sum_{i &#x3D; 1}^{n} w_i f_i(x, y) - \sum_{x} \tilde{P}(x) \ln Z_w(x)<br>$$</p>
<p>改进迭代算法的思路是，假设最大熵模型当前的参数向量是 $w &#x3D; (w_1, w_2, \dots, w_n)^{T}$，我们希望找到一个新的参数向量 $w + \delta &#x3D; (w_1 + \delta_1, \dots, w_n + \delta_n)^{T}$，使得模型的对数似然函数增值。</p>
<p><strong>算法步骤</strong></p>
<p><strong>输入</strong>：特征函数 $f_1, f_2, \dots, f_n$；经验分布 $\tilde{P}(X, Y)$；模型 $P_w(y | x)$</p>
<p><strong>输出</strong>：最优参数值 $w_i^{\ast}$；最优模型 $P_{w^{\ast}}$</p>
<p><strong>步骤1</strong>：对所有 $i \in {1, 2, \dots, n}$，取初值 $w_i &#x3D; 0$。</p>
<p><strong>步骤2</strong>：对每一 $i \in {1, 2, \dots, n}$，执行以下操作：</p>
<p>首先，令 $\delta_i$ 为下列方程的解：</p>
<p>$$<br>\sum_{x, y} \tilde{P}(x) P(y | x) f_i(x, y) \exp \left(\delta_i f^{\Sigma}(x, y) \right) &#x3D; E_{\tilde{P}}(f_i)<br>$$</p>
<p>其中，$f^{\Sigma}(x, y)$ 定义为：</p>
<p>$$<br>f^{\Sigma}(x, y) &#x3D; \sum_{i &#x3D; 1}^{n} f_i(x, y)<br>$$</p>
<p>然后，更新 $w_i$ 的值：</p>
<p>$$<br>w_i \leftarrow w_i + \delta_i<br>$$</p>
<p><strong>步骤3</strong>：如果不是所有 $w_i$ 都收敛，则重复步骤2。</p>
<h3 id="Quasi-Newton-Method-BFGS"><a href="#Quasi-Newton-Method-BFGS" class="headerlink" title="Quasi-Newton Method : BFGS"></a>Quasi-Newton Method : BFGS</h3><p>对最大熵模型而言，</p>
<p>$$<br>P_w(y | x) &#x3D; \frac{\exp \left(\sum_{i &#x3D; 1}^{n} w_i f_i(x, y) \right)}{\sum_{y} \exp \left(\sum_{i &#x3D; 1}^{n} w_i f_i(x, y) \right)}<br>$$</p>
<p>目标函数：</p>
<p>$$<br>\min_{w \in \mathbb{R}^n} f(w) &#x3D; \sum_{x} \tilde{P}(x) \ln \sum_{y} \exp \left(\sum_{i &#x3D; 1}^{n} w_i f_i(x, y) \right) - \sum_{x, y} \tilde{P}(x, y) \sum_{i &#x3D; 1}^{n} w_i f_i(x, y)<br>$$</p>
<p>相应 $i$ 的梯度有，</p>
<p>$$<br>\frac{\partial f(w)}{\partial w_i} &#x3D; \sum_{x, y} \tilde{P}(x) P_w(y | x) f_i(x, y) - E_{\tilde{p}}(f_i)<br>$$</p>
<p>定义 $g()$</p>
<p>$$<br>g(w) &#x3D; \left(\frac{\partial f(x)}{\partial w_1}, \frac{\partial f(x)}{\partial w_2}, \dots,\frac{\partial f(x)}{\partial w_n} \right)^T<br>$$</p>
<p><strong>算法步骤</strong></p>
<p><strong>输入</strong>：特征函数 $f_1, f_2, \dots, f_n$；经验分布 $\tilde{P}(X, Y)$；目标函数 $f(w)$；梯度 $g(w) &#x3D; \nabla f(w)$；精度要求 $\epsilon$；<br><strong>输出</strong>：最优参数值 $w_i^{\ast}$；最优模型 $P_{w^{\ast}}$</p>
<ol>
<li>选定初始点 $w^{(0)}$，取 $B_0$ 为正定对称矩阵，置 $k &#x3D; 0$。</li>
<li>计算 $g_k &#x3D; g(w^{(k)})$。<br>若 $\lVert g_k \rVert &lt; \epsilon$，则停止计算，得 $w^{*} &#x3D; w^{(k)}$；否则转第 3 步。</li>
<li>由 $B_k p_k &#x3D; -g_k$ 求出 $p_k$。</li>
<li>一维搜索，求 $\lambda_k$ 使得<br> $$<br> f(w^{(k)} + \lambda_k p_k) &#x3D; \min_{\lambda \geq 0} f(w^{(k)} + \lambda p_k)<br> $$</li>
<li>置 $w^{(k + 1)} &#x3D; w^{(k)} + \lambda_k p_k$。</li>
<li>计算 $g_{k + 1} &#x3D; g(w^{(k + 1)})$。<br>若 $\lVert g_{k + 1} \rVert &lt; \epsilon$，则停止计算，得 $w^{*} &#x3D; w^{(k + 1)}$；否则，按下式求出 $B_{k + 1}$：<br> $$<br> B_{k + 1} &#x3D; B_k + \frac{y_k y_k^T}{y_k^T \delta_k} - \frac{B_k \delta_k \delta_k^T B_k}{\delta_k^T B_k \delta_k}<br> $$<br> 其中，<br> $$<br> y_k &#x3D; g_{k + 1} - g_k, \quad \delta_k &#x3D; w^{(k + 1)} - w^{(k)}<br> $$</li>
<li>置 $k &#x3D; k + 1$，转第 3 步。</li>
</ol>
<p><strong>补充说明</strong></p>
<p>在 BFGS 算法中，$B_k$ 是对目标函数 <em><strong>Hessian</strong></em> 矩阵的近似。初始时 $B_0$ 通常取为单位矩阵或其他对称正定矩阵。每次迭代后，$B_k$ 按如下公式更新：</p>
<p>$$<br>B_{k + 1} &#x3D; B_k + \frac{y_k y_k^T}{y_k^T \delta_k} - \frac{B_k \delta_k \delta_k^T B_k}{\delta_k^T B_k \delta_k}<br>$$</p>
<p>其中，</p>
<ul>
<li>$\delta_k &#x3D; w^{(k + 1)} - w^{(k)}$ 表示参数的变化，</li>
<li>$y_k &#x3D; g_{k + 1} - g_k$ 表示梯度的变化。</li>
</ul>
<p>$B_k$ 的更新保证了其对称正定性，并逐步逼近真实的 Hessian 矩阵，从而提升搜索方向的准确性和收敛速度。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://ddccffq.github.io/2025/06/02/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" data-id="cmfdjuvi10014qobi23jq5qsp" data-title="最大熵模型" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/06/03/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          上下文无关文法
        
      </div>
    </a>
  
  
    <a href="/2025/06/01/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">条件随机场</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/">Computer Network</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Application-Layer/">Application Layer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Data-Link-Layer/">Data Link Layer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Introduction/">Introduction</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Network-Layer/">Network Layer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Transport-Layer/">Transport Layer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Wireless-and-Mobile-Networks/">Wireless and Mobile Networks</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Wireshark/">Wireshark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BD%A2%E5%BC%8F%E8%AF%AD%E8%A8%80%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%9C%BA/">形式语言与自动机</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/GitHub-Pages/" rel="tag">GitHub Pages</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/" rel="tag">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MathJax/" rel="tag">MathJax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/GitHub-Pages/" style="font-size: 10px;">GitHub Pages</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/MathJax/" style="font-size: 10px;">MathJax</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 20px;">算法</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">May 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/06/17/Wireshark-Homework/">Wireshark Homework</a>
          </li>
        
          <li>
            <a href="/2025/06/10/Introduction/">Introduction</a>
          </li>
        
          <li>
            <a href="/2025/06/09/Wireless-and-Mobile-Networks/">Wireless and Mobile Networks</a>
          </li>
        
          <li>
            <a href="/2025/06/08/The-Transport-Layer/">The Transport Layer</a>
          </li>
        
          <li>
            <a href="/2025/06/07/The-Application-Layer/">The Application Layer</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>