<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>条件随机场 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="本章仅讨论条件随机场在 标注问题（tagging problem） 的应用，因此主要讲述 线性链（linear chain） 条件随机场。 概率无向图模型成对马尔可夫性节点 $u$、$v$ 和所有其他节点 $O$，对应的随机变量分别为 $Y_u$、$Y_v$、$Y_O$（$Y$ 表示随机变量）。它们具有以下概率关系：$$P(Y_u, Y_v | Y_O) &#x3D; P(Y_u | Y_O) P">
<meta property="og:type" content="article">
<meta property="og:title" content="条件随机场">
<meta property="og:url" content="https://ddccffq.github.io/2025/06/01/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="本章仅讨论条件随机场在 标注问题（tagging problem） 的应用，因此主要讲述 线性链（linear chain） 条件随机场。 概率无向图模型成对马尔可夫性节点 $u$、$v$ 和所有其他节点 $O$，对应的随机变量分别为 $Y_u$、$Y_v$、$Y_O$（$Y$ 表示随机变量）。它们具有以下概率关系：$$P(Y_u, Y_v | Y_O) &#x3D; P(Y_u | Y_O) P">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-06-01T05:55:26.000Z">
<meta property="article:modified_time" content="2025-09-10T05:27:30.762Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="算法">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://ddccffq.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-条件随机场" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/06/01/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/" class="article-date">
  <time class="dt-published" datetime="2025-06-01T05:55:26.000Z" itemprop="datePublished">2025-06-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>►<a class="article-category-link" href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      条件随机场
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>本章仅讨论条件随机场在 <strong>标注问题（tagging problem）</strong> 的应用，因此主要讲述 <strong>线性链（linear chain）</strong> 条件随机场。</p>
<h2 id="概率无向图模型"><a href="#概率无向图模型" class="headerlink" title="概率无向图模型"></a>概率无向图模型</h2><h3 id="成对马尔可夫性"><a href="#成对马尔可夫性" class="headerlink" title="成对马尔可夫性"></a>成对马尔可夫性</h3><p>节点 $u$、$v$ 和所有其他节点 $O$，对应的随机变量分别为 $Y_u$、$Y_v$、$Y_O$（$Y$ 表示随机变量）。它们具有以下概率关系：<br>$$<br>P(Y_u, Y_v | Y_O) &#x3D; P(Y_u | Y_O) P(Y_v | Y_O)<br>$$</p>
<h3 id="局部马尔可夫性"><a href="#局部马尔可夫性" class="headerlink" title="局部马尔可夫性"></a>局部马尔可夫性</h3><p>节点 $v$，$W$ 是与 $v$ 相邻的所有节点，$O$ 是其余节点。它们具有以下概率关系：<br>$$<br>P(Y_v, Y_O | Y_W) &#x3D; P(Y_v | Y_W) P(Y_O | Y_W)<br>$$</p>
<h3 id="全局马尔可夫性"><a href="#全局马尔可夫性" class="headerlink" title="全局马尔可夫性"></a>全局马尔可夫性</h3><p>节点集合 $A$、$B$、$C$，其中 $A$ 和 $B$ 被 $C$ 分离。它们具有以下概率关系：<br>$$<br>P(Y_A, Y_B | Y_C) &#x3D; P(Y_A | Y_C) P(Y_B | Y_C)<br>$$</p>
<h3 id="Definition-概率无向图模型"><a href="#Definition-概率无向图模型" class="headerlink" title="Definition: 概率无向图模型"></a>Definition: 概率无向图模型</h3><p>如果联合概率分布 $P(Y)$ 满足上述三个马尔可夫性质，就称此联合概率分布为概率无向图模型。</p>
<h3 id="Definition-团与最大团"><a href="#Definition-团与最大团" class="headerlink" title="Definition: 团与最大团"></a>Definition: 团与最大团</h3><p><strong>团（Clique）：</strong> 图中的一个子集，其中任意两个节点都相邻连接。</p>
<p><strong>最大团（Maximum Clique）：</strong> 不能再添加其他节点的团，即包含所有可能相邻节点的最大子集。</p>
<h3 id="概率无向图模型的因子分解"><a href="#概率无向图模型的因子分解" class="headerlink" title="概率无向图模型的因子分解"></a>概率无向图模型的因子分解</h3><p>$$<br>\begin{align}<br>P(Y) &amp;&#x3D; \frac{1}{Z} \prod_{C} \psi_{C}(Y_C), \quad C \text{ is a maximum clique}<br>\<br>Z &amp;&#x3D; \sum_{Y} \prod_{C} \psi_{C}(Y_C), \quad Z \text{ is normalization factor}<br>\<br>\psi_{C}(Y_C) &amp;&#x3D; \exp{-E(Y_C) }<br>\end{align}<br>$$</p>
<p>其中，$\psi$ 函数称为<strong>势函数</strong>，常用<strong>指数函数</strong>定义势函数。</p>
<p>$$<br>\psi_{C}(Y_{C}) &#x3D; e ^{- H_{C}(Y_{C})}<br>$$</p>
<p>$H_{C}(Y_{C})$ 是一个定义在变量 $Y_{C}$ 上的实值函数，常见形式为</p>
<p>$$<br>H_{C}(Y_{C}) &#x3D; \sum_{u,v \in C, u \neq v} \alpha_{uv} x_u x_v + \sum_{v \in C} \beta_v x_v<br>$$</p>
<p>其中，$\alpha_{uv}$ 和 $\beta_{v}$ 是参数。</p>
<hr>
<h2 id="CRF"><a href="#CRF" class="headerlink" title="CRF"></a>CRF</h2><h3 id="Definition-线性链条件随机场"><a href="#Definition-线性链条件随机场" class="headerlink" title="Definition: 线性链条件随机场"></a>Definition: 线性链条件随机场</h3><p>我们假设 $X$ 和 $Y$ 是随机变量。如果随机变量 $Y$ 是一个马尔可夫随机场，即满足：<br>$$<br>P(Y_v | X, Y_w, w \neq v) &#x3D; P(Y_v | X, Y_w, w \sim v)<br>$$<br>其中 $w \sim v$ 表示节点 $v$ 与节点 $w$ 相邻。</p>
<blockquote>
<p>通常情况下，我们认为 $X$ 与 $Y$ 具有相同的结构。</p>
</blockquote>


<div align = "center"><em>图1：线性链示例</em></div>

<p>我们有如下概率关系。<br>$$<br>P(Y_i | X, Y_1, \dots, Y_{i-1}, Y_{i+1}, \dots, Y_n) &#x3D; P(Y_i | X, Y_{i - 1}, Y_{i + 1})<br>$$</p>
<h3 id="条件随机场的参数化形式"><a href="#条件随机场的参数化形式" class="headerlink" title="条件随机场的参数化形式"></a>条件随机场的参数化形式</h3><p>$$<br>P(\mathbf{y} | \mathbf{x}) &#x3D; \frac{1}{Z(\mathbf{x})} \exp \left(\sum_{i,k}\lambda_k t_k(y_{i -1}, y_i, \mathbf{x}, i) + \sum_{i,l}\mu_l s_l(y_i, \mathbf{x}, i))\right)<br>$$</p>
<p>其中，</p>
<p>$$<br>Z(\mathbf{x}) &#x3D; \sum_{\mathbf{y}} \exp \left(\sum_{i,k}\lambda_k t_k(y_{i -1}, y_i, \mathbf{x}, i) + \sum_{i,l}\mu_l s_l(y_i, \mathbf{x}, i)\right)<br>$$</p>
<p>其中，$t_k$ 和 $s_l$ 是特征函数，$\lambda_k$ 和 $\mu_l$ 是对应的权重参数。</p>
<p><strong>Simplification</strong></p>
<p>$$<br>f_k(y_{i-1}, y_i, \mathbf{x}, i) &#x3D;<br>\begin{cases}<br>t_k(y_{i-1}, y_i, \mathbf{x}, i), \quad &amp;k &#x3D; 1,2, \dots,K_1 \\<br>s_l(y_i, \mathbf{x}, i), \quad &amp;k &#x3D; K_1 + l; \text{ } l &#x3D; 1,2,\dots, K_2<br>\end{cases}<br>$$</p>
<p>$$<br>f_k(\mathbf{y}, \mathbf{x}) &#x3D; \sum_{i&#x3D;1}^{n} f_k(y_{i-1}, y_i, \mathbf{x}, i), \quad k &#x3D; 1,2,\dots,K<br>$$</p>
<p>$$<br>w_k &#x3D;<br>\begin{cases}<br>\lambda_k, &amp;k &#x3D; 1,2,\dots,K_1 \\<br>\mu_l, &amp;k &#x3D; K_1 + l; \text{ } l &#x3D; 1, 2, \dots, K_2<br>\end{cases}<br>$$<br>即，</p>
<p>$$<br>\begin{align*}<br>P(\mathbf{y} \mid \mathbf{x}) &amp;&#x3D; \frac{1}{Z(\mathbf{x})} \exp\left(\sum_{k&#x3D;1}^{K} w_k f_k(\mathbf{y}, \mathbf{x})\right) \\<br>Z(\mathbf{x}) &amp;&#x3D; \sum_{\mathbf{y}} \exp\left(\sum_{k&#x3D;1}^{K} w_k f_k(\mathbf{y}, \mathbf{x})\right)<br>\end{align*}<br>$$<br>注意，这里的 $\sum_{\mathbf{y}}$ 是在对所有可能的标签序列求和，而不仅仅是一个确定的标签序列。</p>
<p>最后，</p>
<p>$$<br>\begin{align}<br>P_{\mathbf{w}}(\mathbf{y} \mid \mathbf{x}) &#x3D; \frac{\exp(\vec{w} \cdot \vec{F}(\mathbf{y}, \mathbf{x}))}{Z_{\mathbf{w}}(\mathbf{x})}<br>\end{align}<br>$$</p>
<p>$$<br>Z_{\mathbf{w}}(\mathbf{x}) &#x3D; \sum_{\mathbf{y}} \exp(\vec{w} \cdot \vec{F}(\mathbf{y}, \mathbf{x}))<br>$$</p>
<h3 id="矩阵形式"><a href="#矩阵形式" class="headerlink" title="矩阵形式"></a>矩阵形式</h3><p>对于每个标签序列，我们引入特殊的起始点和结束点标签，$y_0 &#x3D; \text{start}$ 和 $y_{n+1} &#x3D; \text{stop}$。对于观测序列 $\mathbf{x}$ 中的每个位置 $i &#x3D; 1,2,\dots,n+1$，我们可以定义一个矩阵 $M_i \in \mathbb{R}^{m \times m}$：</p>
<p>$$<br>\begin{align*}<br>M_i(\mathbf{x}) &amp;&#x3D; [M_i(y_{i-1}, y_i | \mathbf{x})]<br>\\<br>M_i(y_{i-1}, y_i |\mathbf{x}) &amp;&#x3D; \exp \left(W_i(y_{i-1}, y_i | \mathbf{x})\right)<br>\\<br>W_i(y_{i-1}, y_i |\mathbf{x}) &amp;&#x3D; \sum_{k&#x3D;1}^{K}w_kf_k(y_{i-1},y_i,\mathbf{x},i)<br>\end{align*}<br>$$</p>
<p>因此：<br>$$<br>P_w(\mathbf{y} |\mathbf{x}) &#x3D; \frac{1}{Z_w(\mathbf{x})} \prod_{i&#x3D;1}^{n+1} M_i(y_{i-1}, y_i |\mathbf{x})<br>$$</p>
<p>特别地：<br>$$<br>Z_w(\mathbf{x}) &#x3D; [M_1(\mathbf{x})M_2(\mathbf{x}) \cdots M_{n+1}(\mathbf{x})]_{\text{start},\text{stop}}<br>$$</p>
<p>也就是矩阵 $(\text{start}, \text{stop})$ 位置上的元素。</p>
<p>矩阵形式不难理解，CRF 中的 $M_i(\mathbf{x})$ 矩阵就是在每个位置 $i$ 上，枚举所有可能的标签对 $(y_{i-1}, y_i)$，并计算它们的转移得分。例如 $m &#x3D; 2$，$Y &#x3D; {A, B}$，则 $M_1$ 为：</p>
<p>$$<br>M_1(\mathbf{x}) &#x3D;<br>\begin{bmatrix}<br>M_1(A, A \mid \mathbf{x}) &amp; M_1(A, B \mid \mathbf{x}) \\<br>M_1(B, A \mid \mathbf{x}) &amp; M_1(B, B \mid \mathbf{x})<br>\end{bmatrix}<br>$$</p>
<hr>
<h2 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h2><p>接下来给出计算 $P(Y_i &#x3D; y_i |\mathbf{x})$、$P(Y_{i - 1} &#x3D; y_{i - 1}, Y_i &#x3D; y_i |\mathbf{x})$ 以及相应数学期望的解决方法。</p>
<h3 id="前向-后向算法"><a href="#前向-后向算法" class="headerlink" title="前向-后向算法"></a>前向-后向算法</h3><p>对于每个索引 $i &#x3D; 0, 1, \dots, n + 1$，我们定义前向列向量 $\alpha_i(x)$：</p>
<p>$$<br>\alpha_0(y|\mathbf{x}) &#x3D;<br>\begin{cases}<br>1, &amp;y &#x3D; \text{start}<br>\\<br>0, &amp;\text{其他情况}<br>\end{cases}<br>$$</p>
<p>递推公式为：</p>
<p>$$<br>\alpha_i^T(y_i|\mathbf{x}) &#x3D; \alpha_{i-1}^T (y_{i-1}|\mathbf{x}) [M_i(y_{i-1},y_i|\mathbf{x})],\quad i &#x3D; 1,2,\dots,n+1 \tag{forward}<br>$$</p>
<p>同样地，我们定义后向行向量：</p>
<p>$$<br>\begin{align}<br>\beta_{n+1}(y_{n+1}|\mathbf{x}) &amp;&#x3D;<br>\begin{cases}<br>1, &amp;y_{n+1} &#x3D; \text{stop}<br>\\<br>0, &amp;\text{其他情况}<br>\end{cases}<br>\\<br>\beta_i(y_i|\mathbf{x})&amp; &#x3D; [M_{i+1}(y_i,y_{i+1}|\mathbf{x})] \beta_{i+1}(y_{i+1}|\mathbf{x}) \tag{backward}<br>\end{align}<br>$$</p>
<h3 id="概率计算"><a href="#概率计算" class="headerlink" title="概率计算"></a>概率计算</h3><p>$$<br>P(Y_i &#x3D; y_i | \mathbf{x}) &#x3D; \frac{\alpha_i^T(y_i | \mathbf{x}) \beta_i(y_i | \mathbf{x})}{Z(\mathbf{x})}<br>$$</p>
<p>$$<br>P(Y_{i-1} &#x3D; y_{i-1}, Y_i &#x3D; y_i |\mathbf{x}) &#x3D; \frac{\alpha_{i-1}^T(y_{i-1} |\mathbf{x}) M_i(y_{i-1},y_i |\mathbf{x}) \beta_i(y_i |\mathbf{x})}{Z(\mathbf{x})}<br>$$</p>
<p>其中：</p>
<p>$$<br>Z(\mathbf{x}) &#x3D; \alpha_n^T(\mathbf{x})\mathbf{1} &#x3D; \mathbf{1}^T \beta_1(\mathbf{x})<br>$$</p>
<p><strong>可以仿照隐马尔科夫模型计算相似问题时引入 $\alpha$ 和 $\beta$ 矩阵</strong>，</p>
<h4 id="前向向量矩阵-alpha"><a href="#前向向量矩阵-alpha" class="headerlink" title="前向向量矩阵 $\alpha$"></a>前向向量矩阵 $\alpha$</h4><p>$$<br>\alpha &#x3D; \begin{bmatrix}<br>\alpha_0(A) &amp; \alpha_0(B) &amp; \cdots &amp; \alpha_0(N) \\[10pt]<br>\alpha_1(A) &amp; \alpha_1(B) &amp; \cdots &amp; \alpha_1(N) \\[10pt]<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\[10pt]<br>\alpha_{n+1}(A) &amp; \alpha_{n+1}(B) &amp; \cdots &amp; \alpha_{n+1}(N)<br>\end{bmatrix}^{T} \tag{CRF-1}<br>$$</p>
<p>每一行表示在位置 $i$ 的前向向量 $\alpha_i$，每一列对应一个标签 $y_i \in \mathcal{Y}$。</p>
<h4 id="后向向量矩阵-beta"><a href="#后向向量矩阵-beta" class="headerlink" title="后向向量矩阵 $\beta$"></a>后向向量矩阵 $\beta$</h4><p>$$<br>\beta &#x3D; \begin{bmatrix}<br>\beta_0(A) &amp; \beta_0(B) &amp; \cdots &amp; \beta_0(N) \\[10pt]<br>\beta_1(A) &amp; \beta_1(B) &amp; \cdots &amp; \beta_1(N) \\[10pt]<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\[10pt]<br>\beta_{n+1}(A) &amp; \beta_{n+1}(B) &amp; \cdots &amp; \beta_{n+1}(N)<br>\end{bmatrix} \tag{CRF-2}<br>$$</p>
<p>每一行表示在位置 $i$ 的后向向量 $\beta_i$，每一列对应一个标签 $y_i \in \mathcal{Y}$。</p>
<h3 id="期望值计算"><a href="#期望值计算" class="headerlink" title="期望值计算"></a>期望值计算</h3><p>比较复杂，详情参考《统计学习方法》</p>
<hr>
<h2 id="优化学习算法"><a href="#优化学习算法" class="headerlink" title="优化学习算法"></a>优化学习算法</h2><p>优化学习算法涉及改进迭代尺度法、梯度下降法以及拟牛顿法。这些方法曾在最大熵的学习算法中提及，可以比对学习。</p>
<h3 id="改进的迭代尺度法"><a href="#改进的迭代尺度法" class="headerlink" title="改进的迭代尺度法"></a>改进的迭代尺度法</h3><p>已知训练数据集，由此可知经验概率分布 $\tilde{P}(X, Y)$。可以通过极大化训练数据的对数似然函数来求模型参数。</p>
<p>训练数据的对数似然函数为：</p>
<p>$$<br>L(w) &#x3D; L_{\tilde{P}}(P_{w}) &#x3D; \sum_{\mathbf{x} ,\mathbf{y}} \tilde{P}(\mathbf{x} ,\mathbf{y}) \log P_{w}(\mathbf{y} |\mathbf{x})<br>$$</p>
<p>若</p>
<p>$$<br>\begin{align*}<br>P(\mathbf{y} \mid \mathbf{x}) &amp;&#x3D; \frac{1}{Z(\mathbf{x})} \exp\left(\sum_{k&#x3D;1}^{K} w_k f_k(\mathbf{y}, \mathbf{x})\right) \\<br>Z(\mathbf{x}) &amp;&#x3D; \sum_{\mathbf{y}} \exp\left(\sum_{k&#x3D;1}^{K} w_k f_k(\mathbf{y}, \mathbf{x})\right)<br>\end{align*}<br>$$</p>
<p>则</p>
<p>$$<br>L(w) &#x3D; \sum_{j &#x3D; 1}^{N} \sum_{k &#x3D; 1}^{K} w_{k} f_{k}(y_j, x_j) - \sum_{j &#x3D; 1}^{N} \log Z_w(x_j)<br>$$</p>
<h3 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h3><p>这里介绍的拟牛顿法是 $\mathbf{BFGS}$ 算法。</p>
<p><strong>输入</strong>：特征函数 $f_1, f_2, \cdots, f_n$；经验分布 $\tilde{P}(X, Y)$；精度要求 $\epsilon$；<br><strong>输出</strong>：最优参数值 $\hat{w}$；最优模型 $P_{\hat{w}}(\mathbf{y} |\mathbf{x})$。</p>
<ol>
<li>选定初始点 $w^{(0)}$，取 $B_0$ 为正定对称矩阵，置 $k &#x3D; 0$。</li>
<li>计算 $g_k &#x3D; g(w^{(k)})$。  若 $\lVert g_k \rVert &lt; \epsilon$，则停止计算，得 $w^{*} &#x3D; w^{(k)}$；否则转第 3 步。</li>
<li>由 $B_k p_k &#x3D; -g_k$ 求出 $p_k$。</li>
<li>一维搜索，求 $\lambda_k$ 使得<br> $$<br> f(w^{(k)} + \lambda_k p_k) &#x3D; \min_{\lambda \geq 0} f(w^{(k)} + \lambda p_k)<br> $$</li>
<li>置 $w^{(k + 1)} &#x3D; w^{(k)} + \lambda_k p_k$。</li>
<li>计算 $g_{k + 1} &#x3D; g(w^{(k + 1)})$。  若 $\lVert g_{k + 1} \rVert &lt; \epsilon$，则停止计算，得 $w^{*} &#x3D; w^{(k + 1)}$；否则，按下式求出 $B_{k + 1}$：<br> $$<br> B_{k + 1} &#x3D; B_k + \frac{y_k y_k^T}{y_k^T \delta_k} - \frac{B_k \delta_k \delta_k^T B_k}{\delta_k^T B_k \delta_k}<br> $$<br> 其中，<br> $$<br> y_k &#x3D; g_{k + 1} - g_k, \quad \delta_k &#x3D; w^{(k + 1)} - w^{(k)}<br> $$</li>
<li>置 $k &#x3D; k + 1$，转第 3 步。</li>
</ol>
<h2 id="条件随机场的预测算法"><a href="#条件随机场的预测算法" class="headerlink" title="条件随机场的预测算法"></a>条件随机场的预测算法</h2><p>采用隐马尔科夫模型相似的预测算法</p>
<h3 id="维特比算法"><a href="#维特比算法" class="headerlink" title="维特比算法"></a>维特比算法</h3><p><strong>输入</strong>：</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://ddccffq.github.io/2025/06/01/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/" data-id="cmfdjuvi0000sqobi8ley1bts" data-title="条件随机场" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/06/02/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          最大熵模型
        
      </div>
    </a>
  
  
    <a href="/2025/05/30/The-Network-Layer/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">The Network Layer</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/">Computer Network</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Application-Layer/">Application Layer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Data-Link-Layer/">Data Link Layer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Introduction/">Introduction</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Network-Layer/">Network Layer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Transport-Layer/">Transport Layer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Network/Wireless-and-Mobile-Networks/">Wireless and Mobile Networks</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Wireshark/">Wireshark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BD%A2%E5%BC%8F%E8%AF%AD%E8%A8%80%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%9C%BA/">形式语言与自动机</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/GitHub-Pages/" rel="tag">GitHub Pages</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/" rel="tag">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MathJax/" rel="tag">MathJax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/GitHub-Pages/" style="font-size: 10px;">GitHub Pages</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/MathJax/" style="font-size: 10px;">MathJax</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 20px;">算法</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">May 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/06/17/Wireshark-Homework/">Wireshark Homework</a>
          </li>
        
          <li>
            <a href="/2025/06/10/Introduction/">Introduction</a>
          </li>
        
          <li>
            <a href="/2025/06/09/Wireless-and-Mobile-Networks/">Wireless and Mobile Networks</a>
          </li>
        
          <li>
            <a href="/2025/06/08/The-Transport-Layer/">The Transport Layer</a>
          </li>
        
          <li>
            <a href="/2025/06/07/The-Application-Layer/">The Application Layer</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>